{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "47143964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the libraries \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing, metrics\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "sns.set(style=\"white\", color_codes=True)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "aa140e07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CUST_ID</th>\n",
       "      <th>BALANCE</th>\n",
       "      <th>BALANCE_FREQUENCY</th>\n",
       "      <th>PURCHASES</th>\n",
       "      <th>ONEOFF_PURCHASES</th>\n",
       "      <th>INSTALLMENTS_PURCHASES</th>\n",
       "      <th>CASH_ADVANCE</th>\n",
       "      <th>PURCHASES_FREQUENCY</th>\n",
       "      <th>ONEOFF_PURCHASES_FREQUENCY</th>\n",
       "      <th>PURCHASES_INSTALLMENTS_FREQUENCY</th>\n",
       "      <th>CASH_ADVANCE_FREQUENCY</th>\n",
       "      <th>CASH_ADVANCE_TRX</th>\n",
       "      <th>PURCHASES_TRX</th>\n",
       "      <th>CREDIT_LIMIT</th>\n",
       "      <th>PAYMENTS</th>\n",
       "      <th>MINIMUM_PAYMENTS</th>\n",
       "      <th>PRC_FULL_PAYMENT</th>\n",
       "      <th>TENURE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C10001</td>\n",
       "      <td>40.900749</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>95.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>95.4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>201.802084</td>\n",
       "      <td>139.509787</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C10002</td>\n",
       "      <td>3202.467416</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6442.945483</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>7000.0</td>\n",
       "      <td>4103.032597</td>\n",
       "      <td>1072.340217</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C10003</td>\n",
       "      <td>2495.148862</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>773.17</td>\n",
       "      <td>773.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>7500.0</td>\n",
       "      <td>622.066742</td>\n",
       "      <td>627.284787</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C10004</td>\n",
       "      <td>1666.670542</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>1499.00</td>\n",
       "      <td>1499.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>205.788017</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7500.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C10005</td>\n",
       "      <td>817.714335</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.00</td>\n",
       "      <td>16.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>678.334763</td>\n",
       "      <td>244.791237</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CUST_ID      BALANCE  BALANCE_FREQUENCY  PURCHASES  ONEOFF_PURCHASES  \\\n",
       "0  C10001    40.900749           0.818182      95.40              0.00   \n",
       "1  C10002  3202.467416           0.909091       0.00              0.00   \n",
       "2  C10003  2495.148862           1.000000     773.17            773.17   \n",
       "3  C10004  1666.670542           0.636364    1499.00           1499.00   \n",
       "4  C10005   817.714335           1.000000      16.00             16.00   \n",
       "\n",
       "   INSTALLMENTS_PURCHASES  CASH_ADVANCE  PURCHASES_FREQUENCY  \\\n",
       "0                    95.4      0.000000             0.166667   \n",
       "1                     0.0   6442.945483             0.000000   \n",
       "2                     0.0      0.000000             1.000000   \n",
       "3                     0.0    205.788017             0.083333   \n",
       "4                     0.0      0.000000             0.083333   \n",
       "\n",
       "   ONEOFF_PURCHASES_FREQUENCY  PURCHASES_INSTALLMENTS_FREQUENCY  \\\n",
       "0                    0.000000                          0.083333   \n",
       "1                    0.000000                          0.000000   \n",
       "2                    1.000000                          0.000000   \n",
       "3                    0.083333                          0.000000   \n",
       "4                    0.083333                          0.000000   \n",
       "\n",
       "   CASH_ADVANCE_FREQUENCY  CASH_ADVANCE_TRX  PURCHASES_TRX  CREDIT_LIMIT  \\\n",
       "0                0.000000                 0              2        1000.0   \n",
       "1                0.250000                 4              0        7000.0   \n",
       "2                0.000000                 0             12        7500.0   \n",
       "3                0.083333                 1              1        7500.0   \n",
       "4                0.000000                 0              1        1200.0   \n",
       "\n",
       "      PAYMENTS  MINIMUM_PAYMENTS  PRC_FULL_PAYMENT  TENURE  \n",
       "0   201.802084        139.509787          0.000000      12  \n",
       "1  4103.032597       1072.340217          0.222222      12  \n",
       "2   622.066742        627.284787          0.000000      12  \n",
       "3     0.000000               NaN          0.000000      12  \n",
       "4   678.334763        244.791237          0.000000      12  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Question-1: Principal Component Analysis\n",
    "\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\deept\\\\Downloads\\\\datasets\\\\datasets\\\\CC GENERAL.csv\")\n",
    "df.head()\n",
    "\n",
    "#Reading the CC General file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f49f10a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CUST_ID                             False\n",
       "BALANCE                             False\n",
       "BALANCE_FREQUENCY                   False\n",
       "PURCHASES                           False\n",
       "ONEOFF_PURCHASES                    False\n",
       "INSTALLMENTS_PURCHASES              False\n",
       "CASH_ADVANCE                        False\n",
       "PURCHASES_FREQUENCY                 False\n",
       "ONEOFF_PURCHASES_FREQUENCY          False\n",
       "PURCHASES_INSTALLMENTS_FREQUENCY    False\n",
       "CASH_ADVANCE_FREQUENCY              False\n",
       "CASH_ADVANCE_TRX                    False\n",
       "PURCHASES_TRX                       False\n",
       "CREDIT_LIMIT                         True\n",
       "PAYMENTS                            False\n",
       "MINIMUM_PAYMENTS                     True\n",
       "PRC_FULL_PAYMENT                    False\n",
       "TENURE                              False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().any()\n",
    "# checking null data in the dataset using isnull() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d191a2fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CUST_ID                             False\n",
       "BALANCE                             False\n",
       "BALANCE_FREQUENCY                   False\n",
       "PURCHASES                           False\n",
       "ONEOFF_PURCHASES                    False\n",
       "INSTALLMENTS_PURCHASES              False\n",
       "CASH_ADVANCE                        False\n",
       "PURCHASES_FREQUENCY                 False\n",
       "ONEOFF_PURCHASES_FREQUENCY          False\n",
       "PURCHASES_INSTALLMENTS_FREQUENCY    False\n",
       "CASH_ADVANCE_FREQUENCY              False\n",
       "CASH_ADVANCE_TRX                    False\n",
       "PURCHASES_TRX                       False\n",
       "CREDIT_LIMIT                        False\n",
       "PAYMENTS                            False\n",
       "MINIMUM_PAYMENTS                    False\n",
       "PRC_FULL_PAYMENT                    False\n",
       "TENURE                              False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.fillna(df.mean(), inplace=True)\n",
    "df.isnull().any()\n",
    "\n",
    "#replacing the null data with the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cc7e2f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8950, 16) (8950,)\n"
     ]
    }
   ],
   "source": [
    "x = df.iloc[:,1:-1]\n",
    "y = df.iloc[:,-1]\n",
    "print(x.shape,y.shape)\n",
    "\n",
    "# x is selecting all rows and all columns from the second column to the second-to-last column. This is equivalent to selecting all columns except for the first and last columns\n",
    "# y is selecting all rows and only the last column.\n",
    "# print(x.shape, y.shape) prints the shape of x and y, which is the number of rows and columns in each subset of data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fc0ea190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>principal component 1</th>\n",
       "      <th>principal component 2</th>\n",
       "      <th>principal component 3</th>\n",
       "      <th>TENURE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4326.383979</td>\n",
       "      <td>921.566882</td>\n",
       "      <td>183.708383</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4118.916665</td>\n",
       "      <td>-2432.846346</td>\n",
       "      <td>2369.969289</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1497.907641</td>\n",
       "      <td>-1997.578694</td>\n",
       "      <td>-2125.631328</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1394.548536</td>\n",
       "      <td>-1488.743453</td>\n",
       "      <td>-2431.799649</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3743.351896</td>\n",
       "      <td>757.342657</td>\n",
       "      <td>512.476492</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   principal component 1  principal component 2  principal component 3  TENURE\n",
       "0           -4326.383979             921.566882             183.708383      12\n",
       "1            4118.916665           -2432.846346            2369.969289      12\n",
       "2            1497.907641           -1997.578694           -2125.631328      12\n",
       "3            1394.548536           -1488.743453           -2431.799649      12\n",
       "4           -3743.351896             757.342657             512.476492      12"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a. Apply PCA on CC dataset.\n",
    "#Datasets can be analyzed with PCA so that redundant features can be removed without losing too much information.\n",
    "pca = PCA(3)   #Instantiate PCA\n",
    "x_pca = pca.fit_transform(x)\n",
    "principalDf = pd.DataFrame(data = x_pca, columns = ['principal component 1', 'principal component 2', 'principal component 3'])\n",
    "finalDf = pd.concat([principalDf, df.iloc[:,-1]], axis = 1)\n",
    "finalDf.head()\n",
    "\n",
    "#PCA(3)- performs principal component analysis (PCA) on dataset x, reducing the dimensionality of the data from the original number of features to 3 principal components.\n",
    "#fit_transform()- method of the PCA object is called on the data x to obtain a transformed version of the data, where each observation is represented by its three principal components.\n",
    "#principalDf- represents the transformed data x_pca and three principal components\n",
    "#finalDf- concatenating principalDf with the last column of the original DataFrame df using pd.concat(). This is likely done to include the target variable (the variable being predicted) with the transformed data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "af5be78a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8950, 3) (8950,)\n"
     ]
    }
   ],
   "source": [
    "# b. Apply k-means algorithm on the PCA result and report your observation if the silhouette score has improved or not?\n",
    "X = finalDf.iloc[:,0:-1]\n",
    "y = finalDf.iloc[:,-1]\n",
    "print(X.shape,y.shape)\n",
    "\n",
    "#X- predictor variable- contains all rows of finalDf except for the last column, representing the principal components generated by PCA\n",
    "#y- target variable- contains only the last column of finalDf, representing the target variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ab407f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      1.00      0.00       0.0\n",
      "           1       0.00      1.00      0.00       0.0\n",
      "           2       0.00      1.00      0.00       0.0\n",
      "           6       1.00      0.00      0.00     204.0\n",
      "           7       1.00      0.00      0.00     190.0\n",
      "           8       1.00      0.00      0.00     196.0\n",
      "           9       1.00      0.00      0.00     175.0\n",
      "          10       1.00      0.00      0.00     236.0\n",
      "          11       1.00      0.00      0.00     365.0\n",
      "          12       1.00      0.00      0.00    7584.0\n",
      "\n",
      "    accuracy                           0.00    8950.0\n",
      "   macro avg       0.70      0.30      0.00    8950.0\n",
      "weighted avg       1.00      0.00      0.00    8950.0\n",
      "\n",
      "[[   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   1  175   28    0    0    0    0    0    0    0]\n",
      " [   2  173   15    0    0    0    0    0    0    0]\n",
      " [   0  169   27    0    0    0    0    0    0    0]\n",
      " [   0  149   26    0    0    0    0    0    0    0]\n",
      " [   1  188   47    0    0    0    0    0    0    0]\n",
      " [   3  284   78    0    0    0    0    0    0    0]\n",
      " [ 126 5390 2068    0    0    0    0    0    0    0]]\n",
      "\n",
      "Accuracy for our Training dataset with PCA: 0.0\n",
      "Sihouette Score:  0.5109769750121257\n"
     ]
    }
   ],
   "source": [
    "nclusters = 3 # this is the k in kmeans\n",
    "km = KMeans(n_clusters=nclusters)\n",
    "km.fit(X)\n",
    "\n",
    "# predict the cluster for each data point\n",
    "y_cluster_kmeans = km.predict(X)\n",
    "\n",
    "# Summary of the predictions made by the classifier\n",
    "print(classification_report(y, y_cluster_kmeans, zero_division=1))\n",
    "print(confusion_matrix(y, y_cluster_kmeans))\n",
    "\n",
    "#finding the accuracy\n",
    "train_accuracy = accuracy_score(y, y_cluster_kmeans)\n",
    "print(\"\\nAccuracy for our Training dataset with PCA:\", train_accuracy)\n",
    "\n",
    "#Calculating sihouette Score\n",
    "score = metrics.silhouette_score(X, y_cluster_kmeans)\n",
    "print(\"Sihouette Score: \",score)   #ranges from -1 to +1, high value shows that it is matched more\n",
    "\n",
    "#Kmeans()- is used to perform Kmeans clustering on transformed data X with the specified number of clusters\n",
    "#fit()- method is called on the KMeans object to cluster the data.\n",
    "#predict() method is used to assign each data point to a cluster based on the clustering performed by K-means and cluster alignment is stored in y_cluster_kmeans\n",
    "#classification_report()- summary of predictions made by the classifier, Zero_division = parameter is set to 1 to avoid errors when a cluster is not assigned any data points.\n",
    "#confusion matrix- shows the number of true positive, false positive, true negative, and false negative predictions for each class.\n",
    "#metrics.silhouette_score()- The silhouette score is a measure of how similar an object is to its own cluster compared to other clusters and ranges from -1 to 1, where a higher score indicates better clustering.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3869a6dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8950, 16) (8950,)\n"
     ]
    }
   ],
   "source": [
    "# c. Perform Scaling+PCA+K-Means and report performance.\n",
    "\n",
    "x = df.iloc[:,1:-1]\n",
    "y = df.iloc[:,-1]\n",
    "print(x.shape,y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "91f96869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>principal component 1</th>\n",
       "      <th>principal component 2</th>\n",
       "      <th>principal component 3</th>\n",
       "      <th>TENURE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.718893</td>\n",
       "      <td>-1.072939</td>\n",
       "      <td>0.535727</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.169306</td>\n",
       "      <td>2.509324</td>\n",
       "      <td>0.628095</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.938414</td>\n",
       "      <td>-0.382598</td>\n",
       "      <td>0.161281</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.907503</td>\n",
       "      <td>0.045862</td>\n",
       "      <td>1.521766</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.637830</td>\n",
       "      <td>-0.684975</td>\n",
       "      <td>0.425702</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   principal component 1  principal component 2  principal component 3  TENURE\n",
       "0              -1.718893              -1.072939               0.535727      12\n",
       "1              -1.169306               2.509324               0.628095      12\n",
       "2               0.938414              -0.382598               0.161281      12\n",
       "3              -0.907503               0.045862               1.521766      12\n",
       "4              -1.637830              -0.684975               0.425702      12"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Scale the dataset; This is very important before you apply PCA\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x)\n",
    "X_scaled_array = scaler.transform(x)\n",
    "\n",
    "# Instantiate PCA\n",
    "pca = PCA(3)\n",
    "\n",
    "# Determine transformed features\n",
    "x_pca = pca.fit_transform(X_scaled_array)\n",
    "principalDf = pd.DataFrame(data = x_pca, columns = ['principal component 1', 'principal component 2','principal component 3'])\n",
    "finalDf = pd.concat([principalDf, df.iloc[:,-1]], axis = 1)\n",
    "finalDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a518bb8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8950, 3) (8950,)\n"
     ]
    }
   ],
   "source": [
    "x = finalDf.iloc[:,0:-1]\n",
    "y = finalDf[\"TENURE\"]\n",
    "print(X.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2ea4ab0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      1.00      0.00       0.0\n",
      "           1       0.00      1.00      0.00       0.0\n",
      "           2       0.00      1.00      0.00       0.0\n",
      "           6       1.00      0.00      0.00     139.0\n",
      "           7       1.00      0.00      0.00     135.0\n",
      "           8       1.00      0.00      0.00     128.0\n",
      "           9       1.00      0.00      0.00     118.0\n",
      "          10       1.00      0.00      0.00     151.0\n",
      "          11       1.00      0.00      0.00     262.0\n",
      "          12       1.00      0.00      0.00    4974.0\n",
      "\n",
      "    accuracy                           0.00    5907.0\n",
      "   macro avg       0.70      0.30      0.00    5907.0\n",
      "weighted avg       1.00      0.00      0.00    5907.0\n",
      "\n",
      "[[   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [  30  105    4    0    0    0    0    0    0    0]\n",
      " [  26  108    1    0    0    0    0    0    0    0]\n",
      " [  28   96    4    0    0    0    0    0    0    0]\n",
      " [  27   89    2    0    0    0    0    0    0    0]\n",
      " [  38  107    6    0    0    0    0    0    0    0]\n",
      " [  66  185   11    0    0    0    0    0    0    0]\n",
      " [ 842 3397  735    0    0    0    0    0    0    0]]\n",
      "Accuracy for our Training dataset with PCA: 0.0\n",
      "Sihouette Score:  0.38140394796068733\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.34,random_state=0)\n",
    "nclusters = 3 \n",
    "# this is the k in kmeans\n",
    "km = KMeans(n_clusters=nclusters)\n",
    "km.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "# predict the cluster for each training data point\n",
    "y_clus_train = km.predict(X_train)\n",
    "\n",
    "# Summary of the predictions made by the classifier\n",
    "print(classification_report(y_train, y_clus_train, zero_division=1))\n",
    "print(confusion_matrix(y_train, y_clus_train))\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, y_clus_train)\n",
    "print(\"Accuracy for our Training dataset with PCA:\", train_accuracy)\n",
    "\n",
    "#Calculating sihouette Score\n",
    "score = metrics.silhouette_score(X_train, y_clus_train)\n",
    "print(\"Sihouette Score: \",score)   #ranges from -1 to +1, high value shows that it is matched more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1a5faccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      1.00      0.00       0.0\n",
      "           1       0.00      1.00      0.00       0.0\n",
      "           2       0.00      1.00      0.00       0.0\n",
      "           6       1.00      0.00      0.00      65.0\n",
      "           7       1.00      0.00      0.00      55.0\n",
      "           8       1.00      0.00      0.00      68.0\n",
      "           9       1.00      0.00      0.00      57.0\n",
      "          10       1.00      0.00      0.00      85.0\n",
      "          11       1.00      0.00      0.00     103.0\n",
      "          12       1.00      0.00      0.00    2610.0\n",
      "\n",
      "    accuracy                           0.00    3043.0\n",
      "   macro avg       0.70      0.30      0.00    3043.0\n",
      "weighted avg       1.00      0.00      0.00    3043.0\n",
      "\n",
      "[[   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [  21   41    3    0    0    0    0    0    0    0]\n",
      " [  12   43    0    0    0    0    0    0    0    0]\n",
      " [  10   57    1    0    0    0    0    0    0    0]\n",
      " [  22   35    0    0    0    0    0    0    0    0]\n",
      " [  17   63    5    0    0    0    0    0    0    0]\n",
      " [  30   69    4    0    0    0    0    0    0    0]\n",
      " [ 450 1765  395    0    0    0    0    0    0    0]]\n",
      "\n",
      "Accuracy for our Testing dataset with PCA: 0.0\n",
      "Sihouette Score:  0.38364262054620335\n"
     ]
    }
   ],
   "source": [
    "# predict the cluster for each testing data point\n",
    "y_clus_test = km.predict(X_test)\n",
    "\n",
    "# Summary of the predictions made by the classifier\n",
    "print(classification_report(y_test, y_clus_test, zero_division=1))\n",
    "print(confusion_matrix(y_test, y_clus_test))\n",
    "\n",
    "train_accuracy = accuracy_score(y_test, y_clus_test)\n",
    "print(\"\\nAccuracy for our Testing dataset with PCA:\", train_accuracy)\n",
    "\n",
    "#Calculating sihouette Score\n",
    "score = metrics.silhouette_score(X_test, y_clus_test)\n",
    "print(\"Sihouette Score: \",score)   #ranges from -1 to +1, high value shows that it is matched more\n",
    "\n",
    "\n",
    "#First scale the data Applies the fit_transform() method of the StandardScaler instance to the feature matrix X to perform feature scaling. \n",
    "#This method first computes the mean and standard deviation of each feature in X, and then scales the features such that they have zero mean and unit variance\n",
    "#Then apply PCA to reduce the dimensionality to 3 components. \n",
    "#Then split the data into training and testing sets using the train_test_split() function. \n",
    "#Perform K-means clustering on the training set and test set and predict the cluster for each training data point. \n",
    "#Finally, evaluate the performance of the clustering on the training & training set using classification_report(), confusion_matrix(), accuracy_score(), and silhouette_score() functions from sklearn.metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3859ad21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>PPE</th>\n",
       "      <th>DFA</th>\n",
       "      <th>RPDE</th>\n",
       "      <th>numPulses</th>\n",
       "      <th>numPeriodsPulses</th>\n",
       "      <th>meanPeriodPulses</th>\n",
       "      <th>stdDevPeriodPulses</th>\n",
       "      <th>locPctJitter</th>\n",
       "      <th>...</th>\n",
       "      <th>tqwt_kurtosisValue_dec_28</th>\n",
       "      <th>tqwt_kurtosisValue_dec_29</th>\n",
       "      <th>tqwt_kurtosisValue_dec_30</th>\n",
       "      <th>tqwt_kurtosisValue_dec_31</th>\n",
       "      <th>tqwt_kurtosisValue_dec_32</th>\n",
       "      <th>tqwt_kurtosisValue_dec_33</th>\n",
       "      <th>tqwt_kurtosisValue_dec_34</th>\n",
       "      <th>tqwt_kurtosisValue_dec_35</th>\n",
       "      <th>tqwt_kurtosisValue_dec_36</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.85247</td>\n",
       "      <td>0.71826</td>\n",
       "      <td>0.57227</td>\n",
       "      <td>240</td>\n",
       "      <td>239</td>\n",
       "      <td>0.008064</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.00218</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5620</td>\n",
       "      <td>2.6445</td>\n",
       "      <td>3.8686</td>\n",
       "      <td>4.2105</td>\n",
       "      <td>5.1221</td>\n",
       "      <td>4.4625</td>\n",
       "      <td>2.6202</td>\n",
       "      <td>3.0004</td>\n",
       "      <td>18.9405</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76686</td>\n",
       "      <td>0.69481</td>\n",
       "      <td>0.53966</td>\n",
       "      <td>234</td>\n",
       "      <td>233</td>\n",
       "      <td>0.008258</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.00195</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5589</td>\n",
       "      <td>3.6107</td>\n",
       "      <td>23.5155</td>\n",
       "      <td>14.1962</td>\n",
       "      <td>11.0261</td>\n",
       "      <td>9.5082</td>\n",
       "      <td>6.5245</td>\n",
       "      <td>6.3431</td>\n",
       "      <td>45.1780</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.85083</td>\n",
       "      <td>0.67604</td>\n",
       "      <td>0.58982</td>\n",
       "      <td>232</td>\n",
       "      <td>231</td>\n",
       "      <td>0.008340</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.00176</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5643</td>\n",
       "      <td>2.3308</td>\n",
       "      <td>9.4959</td>\n",
       "      <td>10.7458</td>\n",
       "      <td>11.0177</td>\n",
       "      <td>4.8066</td>\n",
       "      <td>2.9199</td>\n",
       "      <td>3.1495</td>\n",
       "      <td>4.7666</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.41121</td>\n",
       "      <td>0.79672</td>\n",
       "      <td>0.59257</td>\n",
       "      <td>178</td>\n",
       "      <td>177</td>\n",
       "      <td>0.010858</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.00419</td>\n",
       "      <td>...</td>\n",
       "      <td>3.7805</td>\n",
       "      <td>3.5664</td>\n",
       "      <td>5.2558</td>\n",
       "      <td>14.0403</td>\n",
       "      <td>4.2235</td>\n",
       "      <td>4.6857</td>\n",
       "      <td>4.8460</td>\n",
       "      <td>6.2650</td>\n",
       "      <td>4.0603</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.32790</td>\n",
       "      <td>0.79782</td>\n",
       "      <td>0.53028</td>\n",
       "      <td>236</td>\n",
       "      <td>235</td>\n",
       "      <td>0.008162</td>\n",
       "      <td>0.002669</td>\n",
       "      <td>0.00535</td>\n",
       "      <td>...</td>\n",
       "      <td>6.1727</td>\n",
       "      <td>5.8416</td>\n",
       "      <td>6.0805</td>\n",
       "      <td>5.7621</td>\n",
       "      <td>7.7817</td>\n",
       "      <td>11.6891</td>\n",
       "      <td>8.2103</td>\n",
       "      <td>5.0559</td>\n",
       "      <td>6.1164</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 755 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  gender      PPE      DFA     RPDE  numPulses  numPeriodsPulses  \\\n",
       "0   0       1  0.85247  0.71826  0.57227        240               239   \n",
       "1   0       1  0.76686  0.69481  0.53966        234               233   \n",
       "2   0       1  0.85083  0.67604  0.58982        232               231   \n",
       "3   1       0  0.41121  0.79672  0.59257        178               177   \n",
       "4   1       0  0.32790  0.79782  0.53028        236               235   \n",
       "\n",
       "   meanPeriodPulses  stdDevPeriodPulses  locPctJitter  ...  \\\n",
       "0          0.008064            0.000087       0.00218  ...   \n",
       "1          0.008258            0.000073       0.00195  ...   \n",
       "2          0.008340            0.000060       0.00176  ...   \n",
       "3          0.010858            0.000183       0.00419  ...   \n",
       "4          0.008162            0.002669       0.00535  ...   \n",
       "\n",
       "   tqwt_kurtosisValue_dec_28  tqwt_kurtosisValue_dec_29  \\\n",
       "0                     1.5620                     2.6445   \n",
       "1                     1.5589                     3.6107   \n",
       "2                     1.5643                     2.3308   \n",
       "3                     3.7805                     3.5664   \n",
       "4                     6.1727                     5.8416   \n",
       "\n",
       "   tqwt_kurtosisValue_dec_30  tqwt_kurtosisValue_dec_31  \\\n",
       "0                     3.8686                     4.2105   \n",
       "1                    23.5155                    14.1962   \n",
       "2                     9.4959                    10.7458   \n",
       "3                     5.2558                    14.0403   \n",
       "4                     6.0805                     5.7621   \n",
       "\n",
       "   tqwt_kurtosisValue_dec_32  tqwt_kurtosisValue_dec_33  \\\n",
       "0                     5.1221                     4.4625   \n",
       "1                    11.0261                     9.5082   \n",
       "2                    11.0177                     4.8066   \n",
       "3                     4.2235                     4.6857   \n",
       "4                     7.7817                    11.6891   \n",
       "\n",
       "   tqwt_kurtosisValue_dec_34  tqwt_kurtosisValue_dec_35  \\\n",
       "0                     2.6202                     3.0004   \n",
       "1                     6.5245                     6.3431   \n",
       "2                     2.9199                     3.1495   \n",
       "3                     4.8460                     6.2650   \n",
       "4                     8.2103                     5.0559   \n",
       "\n",
       "   tqwt_kurtosisValue_dec_36  class  \n",
       "0                    18.9405      1  \n",
       "1                    45.1780      1  \n",
       "2                     4.7666      1  \n",
       "3                     4.0603      1  \n",
       "4                     6.1164      1  \n",
       "\n",
       "[5 rows x 755 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Question-2: Use pd_speech_features.csv\n",
    "df_pd = pd.read_csv(\"C:\\\\Users\\\\deept\\\\Downloads\\\\datasets\\\\datasets\\\\pd_speech_features.csv\")\n",
    "df_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "87e7d406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                           False\n",
       "gender                       False\n",
       "PPE                          False\n",
       "DFA                          False\n",
       "RPDE                         False\n",
       "                             ...  \n",
       "tqwt_kurtosisValue_dec_33    False\n",
       "tqwt_kurtosisValue_dec_34    False\n",
       "tqwt_kurtosisValue_dec_35    False\n",
       "tqwt_kurtosisValue_dec_36    False\n",
       "class                        False\n",
       "Length: 755, dtype: bool"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pd.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b574bd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_pd.drop('class',axis=1).values\n",
    "Y = df_pd['class'].values\n",
    "\n",
    "# this codes represents dropping the target variable class from main data frame and creates a new data fram X\n",
    "# Y returns the class column from the main data frame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c183c75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a. Perform Scaling\n",
    "\n",
    "#Scaling Data\n",
    "scaler = StandardScaler()\n",
    "X_Scale = scaler.fit_transform(X)\n",
    "\n",
    "#StandardScaler to scale the input X, this is important as it ensures that all the features are on the same scale and prevents features with larger magnitude from dominating the distance calculations\n",
    "#Applies the fit_transform() method of the StandardScaler instance to the feature matrix X to perform feature scaling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3f6df7b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>principal component 1</th>\n",
       "      <th>principal component 2</th>\n",
       "      <th>Principal Component 3</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-10.047372</td>\n",
       "      <td>1.471075</td>\n",
       "      <td>-6.846397</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-10.637725</td>\n",
       "      <td>1.583747</td>\n",
       "      <td>-6.830962</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-13.516185</td>\n",
       "      <td>-1.253543</td>\n",
       "      <td>-6.818695</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-9.155084</td>\n",
       "      <td>8.833594</td>\n",
       "      <td>15.290937</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-6.764470</td>\n",
       "      <td>4.611463</td>\n",
       "      <td>15.637141</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   principal component 1  principal component 2  Principal Component 3  class\n",
       "0             -10.047372               1.471075              -6.846397      1\n",
       "1             -10.637725               1.583747              -6.830962      1\n",
       "2             -13.516185              -1.253543              -6.818695      1\n",
       "3              -9.155084               8.833594              15.290937      1\n",
       "4              -6.764470               4.611463              15.637141      1"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# b. Apply PCA (k=3)\n",
    "\n",
    "# Apply PCA with k =3\n",
    "pca3 = PCA(n_components=3)\n",
    "principalComponents = pca3.fit_transform(X_Scale)\n",
    "\n",
    "principalDf = pd.DataFrame(data = principalComponents, columns = ['principal component 1', 'principal component 2','Principal Component 3'])\n",
    "\n",
    "finalDf = pd.concat([principalDf, df_pd[['class']]], axis = 1)\n",
    "finalDf.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b74b2475",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = finalDf.drop('class',axis=1).values\n",
    "Y = finalDf['class'].values\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3,random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3bc77258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.42      0.52        57\n",
      "           1       0.83      0.93      0.88       170\n",
      "\n",
      "    accuracy                           0.80       227\n",
      "   macro avg       0.75      0.68      0.70       227\n",
      "weighted avg       0.79      0.80      0.79       227\n",
      "\n",
      "[[ 24  33]\n",
      " [ 12 158]]\n",
      "accuracy is 0.801762114537445\n",
      "Sihouette Score:  0.25432090187852174\n"
     ]
    }
   ],
   "source": [
    "# c. Use SVM to report performance\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svmClassifier = SVC()\n",
    "svmClassifier.fit(X_train, Y_train)\n",
    "\n",
    "y_pred = svmClassifier.predict(X_test)\n",
    "\n",
    "# Summary of the predictions made by the classifier\n",
    "print(classification_report(Y_test, y_pred, zero_division=1))\n",
    "print(confusion_matrix(Y_test, y_pred))\n",
    "\n",
    "# Accuracy score\n",
    "glass_acc_svc = accuracy_score(y_pred,Y_test)\n",
    "print('accuracy is',glass_acc_svc)\n",
    "\n",
    "#Calculate sihouette Score\n",
    "score = metrics.silhouette_score(X_test, y_pred)\n",
    "print(\"Sihouette Score: \",score) \n",
    "\n",
    "#It then trains an SVM classifier on the training set, predicts the classes for the test set using the trained classifier, and evaluates the performance using a classification report, confusion matrix, accuracy score, and silhouette score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "37a7432b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
       "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
       "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
       "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
       "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
       "4   5            5.0           3.6            1.4           0.2  Iris-setosa"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Question-3: Apply Linear Discriminant Analysis (LDA) on Iris.csv dataset to reduce dimensionality of data to k=2. \n",
    "#A classifier with a linear decision boundary, generated by fitting class conditional densities to the data and using Bayesâ€™ rule.\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "df_iris = pd.read_csv(\"C:\\\\Users\\\\deept\\\\Downloads\\\\datasets\\\\datasets\\\\Iris.csv\")\n",
    "df_iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "44e1c869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id               False\n",
       "SepalLengthCm    False\n",
       "SepalWidthCm     False\n",
       "PetalLengthCm    False\n",
       "PetalWidthCm     False\n",
       "Species          False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iris.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "18cf4850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4) (150,)\n"
     ]
    }
   ],
   "source": [
    "x = df_iris.iloc[:,1:-1]\n",
    "y = df_iris.iloc[:,-1]\n",
    "print(x.shape,y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "824f81c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2103404f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "988f6270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(105, 2) (45, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "lda = LDA(n_components=2)\n",
    "X_train = lda.fit_transform(X_train, y_train)\n",
    "X_test = lda.transform(X_test)\n",
    "print(X_train.shape,X_test.shape)\n",
    "\n",
    "#fit and transform the scaler object on our training data and only transform our test data.\n",
    "#LabelEncoder to encode our target variable y into numerical values.\n",
    "#(LDA) to perform dimensionality reduction on our input features x. Here, we are reducing the number of input features to 2 using n_components=2\n",
    "#we transform our training and test data using the fit_transform and transform methods of the LDA object respectively\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b278c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question-4: Briefly identify the difference between PCA and LDA\n",
    "\n",
    "PCA (Principal Component Analysis) and LDA (Linear Discriminant Analysis) are both popular techniques in machine learning for dimensionality reduction. However, they have different purposes and methods:\n",
    "\n",
    "Purpose:\n",
    "PCA is used for unsupervised learning and finds the directions of maximum variance in a dataset. It reduces the number of features by transforming the original dataset into a new coordinate system, where the features are uncorrelated and sorted by their variance. PCA is commonly used for data compression, visualization, and noise reduction.\n",
    "LDA, on the other hand, is used for supervised learning and aims to find the linear combinations of features that best separate the classes. It reduces the number of features by projecting the original dataset onto a lower-dimensional space while maximizing the class separability. LDA is commonly used for feature extraction, pattern recognition, and classification.\n",
    "\n",
    "Method:\n",
    "PCA operates by finding the eigenvectors and eigenvalues of the covariance matrix of the data. The eigenvectors represent the directions of maximum variance, and the eigenvalues represent the amount of variance explained by each eigenvector. PCA selects the top k eigenvectors, where k is the desired dimensionality of the reduced dataset.\n",
    "LDA, on the other hand, maximizes the between-class scatter and minimizes the within-class scatter of the data. It involves finding the eigenvectors and eigenvalues of the product of two matrices: the between-class scatter matrix and the within-class scatter matrix. LDA selects the top k eigenvectors that correspond to the largest eigenvalues.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
